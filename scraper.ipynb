{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Acorns Challenge - List All Items on Macy's Website </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ### <center >Jennifer Bryson &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; December 10, 2017 </center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preface: My first approach to solve this problem was to use the Macy's API; however, I applied for the API key and waited for approval for over a day until I decided I best not wait any longer due to the 3 day time constraint.  I'm glad I didn't keep waiting, as I still don't have access."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load in the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from lxml import html\n",
    "from pprint import pprint\n",
    "from urlparse import urlparse\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load in all the required headers to be able to access the HTML code on https://www.macys.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'accept-encoding': 'gzip, deflate, br',\n",
    "    'accept-language': 'en-US,en;q=0.8,de;q=0.6',\n",
    "    'user-agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36',\n",
    "    'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're able to get all the HTML code from https://www.macys.com/ and we will use Xpath to access the it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url_base = 'https://www.macys.com/'\n",
    "main_page = requests.get(url_base, headers=headers)\n",
    "if main_page.status_code != 200:\n",
    "    print('Error: page status code is'), ; print(product_page.status_code) \n",
    "tree = html.fromstring(main_page.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, we have all the HTML code that makes up the main webpage stored as \"tree\".  We can now use \"tree\" to pull out the specific information that we want.  First, we're going to want the urls to all of the categories containing products, e.g. the url to \"Women's Activewear\", the url to \"Women's Basics\", etc.  The following line of code finds us all these urls and stores them in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories = tree.xpath('//*[@id=\"mainNavigationFlyouts\"]/div[*]/div[*]/ul/*/a/@href')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for fun, we can see how many different categories Macy's has for their products.  This will be the number of urls that we must search to get all the items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "783\n"
     ]
    }
   ],
   "source": [
    "print(len(categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create an empty dictionary (with boolean values) where we will store our product names.  The reason we use a dictionary instead of a list is because this will allow us to avoid duplicates of items faster than a list would.  We use boolean values since the value doesn't matter, and boolean values take less memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "product_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to get the products!  \n",
    "\n",
    "We will loop over each category (we have the urls for all the categories from above), and for each category we will do two things: \n",
    "\n",
    "1. Take all the product item names off the page (Macy's has 60 products per page) and add them to the dictionary.  \n",
    "1. Loop over all possible pages for that category (e.g. \"Women's Activewear\" has 40 pages worth of products).\n",
    "\n",
    "Remark 1: This will not give us duplicates of product names because of the way dictionaries store data.\n",
    "\n",
    "Remark 2: This step is the most computationally costly, and it will take approximately 2 hours (on my old slow laptop) to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: page status code is 500\n",
      "['/shop/womens-clothing/dresses/Pageindex/26?id=5449', '/shop/womens-clothing/dresses/Pageindex/26?id=5449']\n",
      "Error: page status code is 500\n",
      "['/shop/womens-clothing/maternity-clothes/Pageindex/2?id=66718', '/shop/womens-clothing/maternity-clothes/Pageindex/2?id=66718']\n",
      "Error: page status code is 500\n",
      "['/shop/womens-clothing/pajamas-and-robes/Pageindex/6?id=59737', '/shop/womens-clothing/pajamas-and-robes/Pageindex/6?id=59737']\n",
      "Error: page status code is 500\n",
      "['/shop/womens-clothing/womens-pants/Pageindex/4?id=157', '/shop/womens-clothing/womens-pants/Pageindex/4?id=157']\n",
      "Error: page status code is 500\n",
      "['/shop/womens-clothing/womens-resort-vacation-wear/Pageindex/2?id=53427', '/shop/womens-clothing/womens-resort-vacation-wear/Pageindex/2?id=53427']\n",
      "Error: page status code is 500\n",
      "['/shop/womens-clothing/womens-skirts/Pageindex/6?id=131', '/shop/womens-clothing/womens-skirts/Pageindex/6?id=131']\n",
      "Error: page status code is 500\n",
      "/shop/womens-clothing/womens-suits?id=67592&cm_sp=us_hdr-_-women-_-67592_suits-%26-suit-separates_COL1\n",
      "https://www.macys.com/shop/womens-clothing/womens-suits?id=67592&cm_sp=us_hdr-_-women-_-67592_suits-%26-suit-separates_COL1\n",
      "Error: page status code is 500\n",
      "['/shop/womens-clothing/womens-sweaters/Pageindex/26?id=260', '/shop/womens-clothing/womens-sweaters/Pageindex/26?id=260']\n",
      "Error: page status code is 500\n",
      "['/shop/handbags-accessories/socks-tights/Pageindex/3?id=40546', '/shop/handbags-accessories/socks-tights/Pageindex/3?id=40546']\n",
      "Error: page status code is 500\n",
      "['/shop/womens-clothing/womens-tops/Pageindex/13?id=255', '/shop/womens-clothing/womens-tops/Pageindex/13?id=255']\n",
      "Error: page status code is 500\n",
      "/shop/womens-clothing/womens-business-attire?id=39096&cm_sp=us_hdr-_-women-_-39096_wear-to-work_COL1\n",
      "https://www.macys.com/shop/womens-clothing/womens-business-attire?id=39096&cm_sp=us_hdr-_-women-_-39096_wear-to-work_COL1\n",
      "Error: page status code is 500\n",
      "['/shop/plus-size-clothing/plus-size-dresses/Pageindex/3?id=37038', '/shop/plus-size-clothing/plus-size-dresses/Pageindex/3?id=37038']\n",
      "Error: page status code is 500\n",
      "['/shop/plus-size-clothing/plus-size-tops/Pageindex/15?id=34048', '/shop/plus-size-clothing/plus-size-tops/Pageindex/15?id=34048']\n",
      "Error: page status code is 500\n",
      "['/shop/petite-clothing/petite-dresses/Pageindex/3?id=55596', '/shop/petite-clothing/petite-dresses/Pageindex/3?id=55596']\n",
      "Error: page status code is 500\n",
      "['/shop/petite-clothing/petite-pants/Pageindex/5?id=55607', '/shop/petite-clothing/petite-pants/Pageindex/5?id=55607']\n",
      "Error: page status code is 500\n",
      "['/shop/petite-clothing/petite-sweaters/Pageindex/5?id=55612', '/shop/petite-clothing/petite-sweaters/Pageindex/5?id=55612']\n",
      "Error: page status code is 404\n",
      "http://social.macys.com/culinary-council/?campaign_id=59&channel_id=1&cm_sp=us_hdr-_-home-_-culinary-council_COL3\n",
      "https://www.macys.com/culinary-council/?campaign_id=59&channel_id=1&cm_sp=us_hdr-_-home-_-culinary-council_COL3\n",
      "Error: page status code is 404\n",
      "http://social.macys.com/lenscrafters/?cm_sp=us_hdr-_-handbags-_-lenscrafters_COL3\n",
      "https://www.macys.com/lenscrafters/?cm_sp=us_hdr-_-handbags-_-lenscrafters_COL3\n",
      "Error: page status code is 404\n",
      " /shop/jewelry-watches/pearls/Jewelry/Fine%20Jewelry?id=2905&cm_sp=us_hdr-_-jewelry-_-pearls_COL1\n",
      "https://www.macys.com/ /shop/jewelry-watches/pearls/Jewelry/Fine%20Jewelry?id=2905&cm_sp=us_hdr-_-jewelry-_-pearls_COL1\n",
      "Error: page status code is 404\n",
      "https://www.customerservice-macys.com/app/answers/detail/a_id/1439?cm_sp=us_hdr-_-jewelry-_-worrynomore-protection-plan_COL2\n",
      "https://www.macys.com/app/answers/detail/a_id/1439?cm_sp=us_hdr-_-jewelry-_-worrynomore-protection-plan_COL2\n",
      "Error: page status code is 404\n",
      "http://social.macys.com/video-channel/?cm_sp=us_hdr-_-watches-_-smart-watch-video-hub_COL4#/video/smartwatch\n",
      "https://www.macys.com/video-channel/?cm_sp=us_hdr-_-watches-_-smart-watch-video-hub_COL4#/video/smartwatch\n",
      "Error: page status code is 404\n",
      "https://www.customerservice-macys.com/app/answers/detail/a_id/1438?cm_sp=us_hdr-_-watches-_-worrynomore-protection-plan_COL4\n",
      "https://www.macys.com/app/answers/detail/a_id/1438?cm_sp=us_hdr-_-watches-_-worrynomore-protection-plan_COL4\n"
     ]
    }
   ],
   "source": [
    "for c in categories:\n",
    "    # first we get the HTML code from a specific category's url (e.g. Women's Activewear) and parse it:\n",
    "    url_c = urlparse(c)\n",
    "    url_c = url_c._replace(netloc=\"www.macys.com\")\n",
    "    url_c = url_c._replace(scheme=\"https\")\n",
    "    product_page = requests.get(url_c.geturl(), headers=headers)\n",
    "    if product_page.status_code != 200:\n",
    "        print('Error: page status code is'), ; print(product_page.status_code) ; print(c) ; print(url_c.geturl())\n",
    "    tree = html.fromstring(product_page.content)\n",
    "    \n",
    "    # one we have the HTML code for that url, we can take the products off of the page (there will be 60/pg)\n",
    "    products_raw = tree.xpath('//a [@class=\"productDescLink\"]/text()')  \n",
    "    products_no_ws = [x.strip() for x in products_raw]  #remove whitespaces\n",
    "    for i in list(filter(None, products_no_ws)):        #remove empty list elements\n",
    "        product_dict.update({i: True})                  #add it to the dictionary - note we will not get duplicates\n",
    "    \n",
    "    # we must loop over all the pages for the category (e.g. Women's Activewear has 40 pages worth of products)\n",
    "    while tree.xpath('//li [@class=\"nextPage \"]/a/@href') != []:\n",
    "        nextpage = tree.xpath('//li [@class=\"nextPage \"]/a/@href')  \n",
    "        next_url = 'https://www.macys.com' + nextpage[0]\n",
    "\n",
    "        next_page = requests.get(next_url, headers=headers)\n",
    "        if next_page.status_code != 200:\n",
    "            print('Error: page status code is'), ; print(next_page.status_code) ; print(nextpage) \n",
    "\n",
    "        tree = html.fromstring(next_page.content)\n",
    "        products_raw = tree.xpath('//a [@class=\"productDescLink\"]/text()')  \n",
    "        products_no_ws = [x.strip() for x in products_raw]\n",
    "        for i in list(filter(None, products_no_ws)):\n",
    "            product_dict.update({i: True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're done!  The names of all the products on Macy's website are now stored as: product_dict.keys()\n",
    "\n",
    "I owe the reader an explaination about all the error messages above though.  Running this multiple times, I saw status_code=500 errors for different pages each time.  My guess is that this is due to the page being unavailable either due to heavy traffic or Macy's updating the page.  If I had more time to work on this project, I would add to my code and tell it to wait a few seconds and retry the URL.  In any case, these error messages give us a clue as to which products may not have made our list.  It'd be a good idea to check the products on these pages and see if they're in our list.  If they aren't, we should add them by rerunning the code on just these sites, which should work since my various trials suggest that the same webpages aren't coming up every time.  Although there are a few webpages that do come up as 404 errors every time.  This is a separate issue: there are 3 URLs of the form www.social.macys.com and 2 URLS of the form www.customerservice-macys.com (as opposed to www.macys.com) so our code has trouble picking up these 5 specific webpages.  Again, given more time, this is fixable.  The only other 404 error is caused by an unwanted space.  Perhaps there are a few weird URLs that just need to be handled individually, otherwise I would need longer than 3 days to create a robust program that handles each unusual scenario.\n",
    "\n",
    "Below we see how many products we found Macy's to have, and we store their names in a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124634\n"
     ]
    }
   ],
   "source": [
    "print(len(product_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'product_dict.keys()' (list) to file 'acorns124634.txt'.\n"
     ]
    }
   ],
   "source": [
    "%store product_dict.keys() >> acorns124634.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How can this be generalized to other merchants?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall process outline can be repeated for other merchants.  Here are the changes that would need to be made:\n",
    "\n",
    "1. You would need to replace this set of headers with headers that the other website desires.\n",
    "1. Change the url_base, the parsed url netloc, and the parsed url scheme to be that of your new merchant.\n",
    "1. Re-do the paths that point to where the product names are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How can we access accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test our product list, we can go to https://www.macys.com/, find a **random** product name, and check our dictionary to see if this product name is there or not.  Repeat (with replacement) this many times and record how many times the product name was on the list vs. not on the list.  By the law of large numbers, the percentage of times the product was on the list will converge to the percentage of product names that we have found -- meaning if we pick 1,000 random product names and if we find that 900 of those were on our list, then we would believe we've found roughly 90% of the product names.  And the more random products we pick, the more accurate this will be.  Of course, if you pick more random products than the total number of products that Macy's has, then you might have well just have individually checked each item, which is a bad idea in terms of speed, so keep the number of products in mind when choosing how many times to repeat the test.\n",
    "\n",
    "Alternatively, due to the way our code works by first selecting a category (like Women's Activewear) and then getting all the products from that category, we could try searching our list for a product on the last page of each category and use the assumption that if our code found that, then it's likely to have found the other products in that category.  This is less mathematically rigorous of an idea though.  Also as mentioned above, one should certainly test for products on the webpages that had the 500 and 404 errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp; 1\\. http://docs.python-guide.org/en/latest/scenarios/scrape/\n",
    "<br>\n",
    "&nbsp; 2\\.  https://stackoverflow.com/questions/2084670/how-to-extract-links-from-a-webpage-using-lxml-xpath-and-python\n",
    "\n",
    "This last reference I didn't end up using, since I couldn't get an API key to access Macy's API, but I still learned a lot from the reference.\n",
    "<br>\n",
    "&nbsp; 3\\.  https://www.digitalocean.com/community/tutorials/how-to-use-web-apis-in-python-3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thank you!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I learned a ton during the process of this coding challenge and found it really fun.  Thank you for this opportunity and interesting challenge.\n",
    "\n",
    "Best,\n",
    "\n",
    "Jennifer Bryson\n",
    "<br>\n",
    "jabryson@uci.edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
